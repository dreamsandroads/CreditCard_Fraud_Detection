{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "\n",
    "# Classifier Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import collections\n",
    "\n",
    "\n",
    "# Other Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cct = pd.read_parquet(\"/home/onyxia/work/df_cct_final.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For \"Use Chip\":\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "features_array = enc.fit_transform(df_cct[[\"Use Chip\"]]).toarray()\n",
    "\n",
    "features_labels = np.hstack(np.array(enc.categories_))\n",
    "\n",
    "df_cct = pd.concat([df_cct, pd.DataFrame(features_array, columns = features_labels)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For \"day_of_week\" : \n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "features_array = enc.fit_transform(df_cct[[\"day_of_week\"]]).toarray()\n",
    "\n",
    "features_labels = np.hstack(np.array(enc.get_feature_names_out()))\n",
    "\n",
    "df_cct = pd.concat([df_cct, pd.DataFrame(features_array, columns = features_labels)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For \"Merchant State\" : \n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore',  max_categories=10) #on se limite aux 10 premières catégories\n",
    "\n",
    "features_array = enc.fit_transform(df_cct[[\"Merchant State\"]]).toarray()\n",
    "\n",
    "features_labels = np.hstack(np.array(enc.get_feature_names_out()))\n",
    "\n",
    "df_cct = pd.concat([df_cct, pd.DataFrame(features_array, columns = features_labels)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only the needed features\n",
    "df_cct = df_cct[['Card', 'Month', 'Day', 'Hours', 'Amount', 'delta_t_s', 'delta_t_s_card', 'amt/daily_income',\n",
    "       'Retired', 'daily_amount', 'nb_daily_declines_card', 'bad_pin',\n",
    "       'insufficient_balance', 'hr_nbt/last_30d_av_hr_nbt', 'last_3d_amt/nbt',\n",
    "       'Chip Transaction', 'Online Transaction',\n",
    "       'Swipe Transaction', 'day_of_week_Friday', 'day_of_week_Monday',\n",
    "       'day_of_week_Saturday', 'day_of_week_Sunday', 'day_of_week_Thursday',\n",
    "       'day_of_week_Tuesday', 'day_of_week_Wednesday', 'Merchant State_CA',\n",
    "       'Merchant State_FL', 'Merchant State_IL', 'Merchant State_NC',\n",
    "       'Merchant State_NY', 'Merchant State_OH', 'Merchant State_PA',\n",
    "       'Merchant State_TX', 'Merchant State_None',\n",
    "       'Merchant State_infrequent_sklearn', 'Is Fraud?']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The classes are heavily skewed we need to solve this issue later.\n",
    "print('No Frauds', round(df_cct['Is Fraud?'].value_counts()[0]/len(df_cct) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(df_cct['Is Fraud?'].value_counts()[1]/len(df_cct) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and Distributing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Since most of our data has already been scaled we should scale the columns that are left to scale (Amount and Time)\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        remainder='passthrough', #passthough features not listed\n",
    "        transformers=[\n",
    "            ('std', RobustScaler(), ['Card', 'Month', 'Day', 'Hours', 'Amount',\n",
    "       'delta_t_s', 'delta_t_s_card', 'amt/daily_income',\n",
    "       'daily_amount', 'nb_daily_declines_card', 'hr_nbt/last_30d_av_hr_nbt', 'last_3d_amt/nbt',])\n",
    "        ])\n",
    "\n",
    "preprocessor.fit_transform(df_cct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fa046f995eb80ac40c0869a1f9df46519f4ada8b8c395ef25dd1aa1a1a2fc63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
